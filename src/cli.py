"""Command-line interface for the bioinformatics agent."""

import argparse
import os
import sys
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# Load .env early so environment variables (OPENROUTER_API_KEY, etc.) are
# available before importing modules that may read them during import-time.
load_dotenv()

from src.agent.agent import create_agent
from src.agent.meeting import run_virtual_lab
from src.virtuallab_workflow.workflow import run_consensus_workflow, run_research_workflow


def save_answer_to_file(answer: str, question: str, output_path: str = None, mode: str = "single") -> str:
    """Save the final answer to a markdown file.

    Args:
        answer: The final answer text
        question: The original question
        output_path: Optional custom output path
        mode: 'single' or 'virtual-lab' for different formatting

    Returns:
        Path to the saved file
    """
    # Generate filename if not provided
    if output_path is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"answer_{timestamp}.md"

    # Ensure it's a Path object
    output_file = Path(output_path)

    # Create parent directories if needed
    output_file.parent.mkdir(parents=True, exist_ok=True)

    # Format the content
    content = f"""# CoScientist Research Report
**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Mode:** {mode.replace('-', ' ').title()}

---

## Research Question

{question}

---

## Final Answer

{answer}

---

*Generated by CoScientist - AI Research Assistant*
"""

    # Write to file
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(content)

    return str(output_file.absolute())


def main():
    """Main CLI entry point."""

    parser = argparse.ArgumentParser(
        description="CoScientist: AI Research Assistant for Biomedical Questions",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Ask a single question
  python -m src.cli --question "How can gene signatures guide drug repositioning?"

  # Virtual Lab mode (multi-agent collaboration)
  python -m src.cli --question "..." --virtual-lab

  # Virtual Lab with more rounds and specialists
  python -m src.cli --question "..." --virtual-lab --rounds 3 --team-size 4

  # With critic feedback loop for quality validation (single agent)
  python -m src.cli --question "..." --with-critic

  # Interactive mode
  python -m src.cli --interactive

  # Save answer to a specific file
  python -m src.cli --question "..." --output results/my_answer.md

  # Use a different model
  python -m src.cli --question "..." --model "openai/gpt-4"

  # Use custom directories for databases and input data
  python -m src.cli --question "..." --data-dir "/path/to/databases" --input-dir "/path/to/Q5"

  # Verbose output to see tool calls
  python -m src.cli --question "..." --verbose
        """,
    )

    parser.add_argument(
        "--question",
        "-q",
        type=str,
        help="Question to ask the agent",
    )
    parser.add_argument(
        "--interactive",
        "-i",
        action="store_true",
        help="Run in interactive mode",
    )
    parser.add_argument(
        "--model",
        "-m",
        type=str,
        default=os.getenv("OPENROUTER_MODEL", "anthropic/claude-sonnet-4"),
        help="Model to use (defaults to OPENROUTER_MODEL env var or claude-sonnet-4)",
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Print verbose output with tool calls",
    )
    parser.add_argument(
        "--with-critic",
        "-c",
        action="store_true",
        help="Enable critic feedback loop for quality validation (single agent mode)",
    )
    parser.add_argument(
        "--virtual-lab",
        "-vl",
        action="store_true",
        help="Enable Virtual Lab mode (multi-agent collaboration)",
    )
    parser.add_argument(
        "--combined",
        action="store_true",
        help="Enable Combined Mode (LangGraph + Consensus)",
    )
    parser.add_argument(
        "--langgraph",
        action="store_true",
        help="Enable LangGraph workflow (without consensus)",
    )
    parser.add_argument(
        "--rounds",
        "-r",
        type=int,
        default=2,
        help="Number of discussion rounds in Virtual Lab mode (default: 2)",
    )
    parser.add_argument(
        "--team-size",
        "-t",
        type=int,
        default=3,
        help="Maximum number of specialist agents in Virtual Lab mode (default: 3)",
    )
    parser.add_argument(
        "--api-key",
        type=str,
        help="API key (Anthropic or OpenRouter, or set env var)",
    )
    parser.add_argument(
        "--data-dir",
        "-d",
        type=str,
        default=os.getenv("DATABASE_DIR", "/home.galaxy4/sumin/project/aisci/Competition_Data"),
        help="Path to main database directory (Drug databases, PPI, GWAS, etc.). Defaults to DATABASE_DIR env var",
    )
    parser.add_argument(
        "--input-dir",
        type=str,
        default=os.getenv("INPUT_DIR"),
        help="Path to question-specific input data (e.g., gene signatures, expression data). Defaults to INPUT_DIR env var, or --data-dir if not set",
    )
    parser.add_argument(
        "--output",
        "-o",
        type=str,
        help="Save the final answer to a file (supports .md, .txt). Auto-generates filename if not specified.",
    )

    args = parser.parse_args()

    # Set default input directory if not specified
    if args.input_dir is None:
        args.input_dir = args.data_dir

    # Check for conflicting modes
    if args.virtual_lab and args.with_critic:
        print("Error: Cannot use both --virtual-lab and --with-critic at the same time.", file=sys.stderr)
        print("Choose one mode: Virtual Lab (multi-agent) OR single agent with critic.", file=sys.stderr)
        sys.exit(1)

    # Determine provider from model name or environment
    provider = None
    if args.model and "/" in args.model:
        # Model format like "anthropic/..." or "openai/..." indicates OpenRouter
        provider = "openrouter"
    else:
        provider = "anthropic"

    # Only create agent for non-virtual-lab modes
    if not args.virtual_lab:
        try:
            agent = create_agent(
                api_key=args.api_key,
                model=args.model,
                provider=provider,
                data_dir=args.data_dir,
                input_dir=args.input_dir
            )
        except ValueError as e:
            print(f"Error: {e}", file=sys.stderr)
            sys.exit(1)

    if args.question:
        # Single question mode
        if args.combined:
            # Combined Mode (LangGraph + Consensus)
            print("\n" + "=" * 60)
            print("COMBINED MODE (LangGraph + Consensus)")
            print("=" * 60)
            print(f"Question: {args.question}")
            print("=" * 60)

            result = run_consensus_workflow(
                question=args.question,
                team_size=args.team_size,
                num_rounds=args.rounds,
                thread_id=f"cli_combined_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                verbose=args.verbose
            )
            
            final_answer = result.get("final_answer", "No answer generated")
            
            print("\n" + "=" * 60)
            print("FINAL ANSWER:")
            print("=" * 60)
            print(final_answer)
            
            output_file = save_answer_to_file(final_answer, args.question, args.output, mode="combined")
            print(f"\n✓ Answer saved to: {output_file}")

        elif args.langgraph:
            # LangGraph Mode (Standard)
            print("\n" + "=" * 60)
            print("LANGGRAPH MODE")
            print("=" * 60)
            print(f"Question: {args.question}")
            print("=" * 60)

            result = run_research_workflow(
                question=args.question,
                enable_human_review=False,
                thread_id=f"cli_langgraph_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                verbose=args.verbose
            )
            
            final_answer = result.get("final_answer", "No answer generated")
            
            print("\n" + "=" * 60)
            print("FINAL ANSWER:")
            print("=" * 60)
            print(final_answer)
            
            output_file = save_answer_to_file(final_answer, args.question, args.output, mode="langgraph")
            print(f"\n✓ Answer saved to: {output_file}")

        elif args.virtual_lab:
            # Virtual Lab mode - multi-agent collaboration
            print("\n" + "=" * 60)
            print("VIRTUAL LAB MODE")
            print("=" * 60)
            print(f"Question: {args.question}")
            print(f"Configuration: {args.rounds} rounds, max {args.team_size} specialists")
            print("=" * 60)

            final_answer = run_virtual_lab(
                question=args.question,
                api_key=args.api_key,
                model=args.model,
                provider=provider,
                num_rounds=args.rounds,
                max_team_size=args.team_size,
                verbose=args.verbose,
                data_dir=args.data_dir,
                input_dir=args.input_dir
            )

            print("\n" + "=" * 60)
            print("FINAL ANSWER (PI Synthesis):")
            print("=" * 60)
            print(final_answer)

            # Save to file
            output_file = save_answer_to_file(final_answer, args.question, args.output, mode="virtual-lab")
            print(f"\n✓ Answer saved to: {output_file}")

        elif args.with_critic:
            initial, critique, final = agent.run_with_critic(args.question, verbose=args.verbose)
            print("\n" + "=" * 60)
            print("INITIAL ANSWER:")
            print("=" * 60)
            print(initial)
            print("\n" + "=" * 60)
            print("CRITIC FEEDBACK:")
            print("=" * 60)
            print(critique)
            print("\n" + "=" * 60)
            print("FINAL REFINED ANSWER:")
            print("=" * 60)
            print(final)

            # Save to file (save the final refined answer)
            output_file = save_answer_to_file(final, args.question, args.output, mode="with-critic")
            print(f"\n✓ Answer saved to: {output_file}")
        else:
            response = agent.run(args.question, verbose=args.verbose)
            print("\n" + "=" * 60)
            print("Final Answer:")
            print("=" * 60)
            print(response)

            # Save to file
            output_file = save_answer_to_file(response, args.question, args.output, mode="single-agent")
            print(f"\n✓ Answer saved to: {output_file}")

    elif args.interactive:
        # Interactive mode
        print("=" * 60)
        print("CoScientist: Interactive Mode")
        if args.virtual_lab:
            print("(Virtual Lab - Multi-Agent Collaboration)")
        print("=" * 60)
        print("Ask biomedical research questions. Type 'exit' or 'quit' to exit.\n")

        while True:
            try:
                question = input("Question: ").strip()
            except EOFError:
                break

            if question.lower() in ["exit", "quit"]:
                print("Goodbye!")
                break

            if not question:
                continue

            if args.virtual_lab:
                # Virtual Lab mode in interactive
                print("\n" + "=" * 60)
                print("VIRTUAL LAB MEETING")
                print("=" * 60)

                final_answer = run_virtual_lab(
                    question=question,
                    api_key=args.api_key,
                    model=args.model,
                    provider=provider,
                    num_rounds=args.rounds,
                    max_team_size=args.team_size,
                    verbose=args.verbose,
                    data_dir=args.data_dir,
                    input_dir=args.input_dir
                )

                print("\n" + "=" * 60)
                print("FINAL ANSWER:")
                print("=" * 60)
                print(final_answer)

                # Auto-save in interactive mode with timestamp
                output_file = save_answer_to_file(final_answer, question, mode="virtual-lab")
                print(f"✓ Saved to: {output_file}")
                print()

            elif args.with_critic:
                initial, critique, final = agent.run_with_critic(question, verbose=args.verbose)
                print("\n" + "=" * 60)
                print("INITIAL ANSWER:")
                print("=" * 60)
                print(initial)
                print("\n" + "=" * 60)
                print("CRITIC FEEDBACK:")
                print("=" * 60)
                print(critique)
                print("\n" + "=" * 60)
                print("FINAL REFINED ANSWER:")
                print("=" * 60)
                print(final)

                # Auto-save in interactive mode
                output_file = save_answer_to_file(final, question, mode="with-critic")
                print(f"✓ Saved to: {output_file}")
                print()
            else:
                response = agent.run(question, verbose=args.verbose)
                print("\n" + "=" * 60)
                print("Answer:")
                print("=" * 60)
                print(response)

                # Auto-save in interactive mode
                output_file = save_answer_to_file(response, question, mode="single-agent")
                print(f"✓ Saved to: {output_file}")
                print()

    else:
        # No input provided
        parser.print_help()


if __name__ == "__main__":
    main()
